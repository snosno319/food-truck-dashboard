name: Daily Scrape

on:
  schedule:
    # Run three times daily on weekdays:
    #   06:00 JST (21:00 UTC prev day) — before lunch, catches fresh data
    #   12:00 JST (03:00 UTC) — midday, catches late-published data
    #   20:00 JST (11:00 UTC) — evening, picks up next-day updates
    - cron: '0 21 * * 0-4'
    - cron: '0 3 * * 1-5'
    - cron: '0 11 * * 1-5'
    # Run once on weekends (Sunday evening JST → scrapes Monday data)
    - cron: '0 21 * * 5'
  workflow_dispatch:

permissions:
  contents: write

concurrency:
  group: "scrapers"
  cancel-in-progress: false

jobs:
  scrape:
    runs-on: ubuntu-latest
    timeout-minutes: 10
    env:
      TZ: Asia/Tokyo
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup Node
        uses: actions/setup-node@v4
        with:
          node-version: "20"
          cache: 'npm'

      - name: Install dependencies
        run: npm ci

      - name: Run scrapers
        run: npm run scrape

      - name: Validate scraped data
        run: node scripts/validate.js

      - name: Health check
        run: node scripts/health-check.js

      - name: Commit and push if changed
        id: commit
        run: |
          git diff --quiet static/data/ && echo "No changes" && echo "changed=false" >> $GITHUB_OUTPUT && exit 0
          git config user.name "github-actions[bot]"
          git config user.email "github-actions[bot]@users.noreply.github.com"
          git add static/data/schedule.json static/data/trucks.json
          git commit -m "chore(data): refresh schedule $(date +%Y-%m-%d)"
          git push
          echo "changed=true" >> $GITHUB_OUTPUT

      - name: Trigger deploy
        if: steps.commit.outputs.changed == 'true'
        uses: actions/github-script@v7
        with:
          script: |
            await github.rest.actions.createWorkflowDispatch({
              owner: context.repo.owner,
              repo: context.repo.repo,
              workflow_id: 'deploy.yml',
              ref: 'main'
            });

